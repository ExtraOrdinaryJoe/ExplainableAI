{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_IoIlNtpR7i5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XAtGssT4SA_M"
   },
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "U4_3eSqrSFo0"
   },
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HSwXak-XSJyP"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Country column\n",
    "ct = ColumnTransformer([(\"Transformer\", OneHotEncoder(), [1,2])], remainder = 'passthrough')\n",
    "X = ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "M15xoINpSUzc"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AsjYwtX8SXZM"
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4lRM9CD9TuG-",
    "outputId": "84b3ac8c-466e-4824-f15a-695d8e39aa03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3avLZs1ISfjo",
    "outputId": "eb7a4141-91e9-4428-ecc2-0dc587969970"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 10:26:21.939343: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "800/800 [==============================] - 1s 973us/step - loss: 0.5045 - accuracy: 0.7732\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 1s 925us/step - loss: 0.4316 - accuracy: 0.7960\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.4136 - accuracy: 0.8098\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3960 - accuracy: 0.8304\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3748 - accuracy: 0.8470\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 1s 972us/step - loss: 0.3608 - accuracy: 0.8511\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 1s 907us/step - loss: 0.3560 - accuracy: 0.8529\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 1s 851us/step - loss: 0.3527 - accuracy: 0.8536\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 1s 823us/step - loss: 0.3508 - accuracy: 0.8561\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 1s 848us/step - loss: 0.3498 - accuracy: 0.8564\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 1s 881us/step - loss: 0.3483 - accuracy: 0.8579\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 1s 880us/step - loss: 0.3476 - accuracy: 0.8576\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 1s 880us/step - loss: 0.3470 - accuracy: 0.8599\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 1s 877us/step - loss: 0.3461 - accuracy: 0.8597\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 1s 874us/step - loss: 0.3450 - accuracy: 0.8595\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 1s 937us/step - loss: 0.3444 - accuracy: 0.8618\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 1s 866us/step - loss: 0.3442 - accuracy: 0.8604\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3433 - accuracy: 0.8614\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 1s 891us/step - loss: 0.3428 - accuracy: 0.8620\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3424 - accuracy: 0.8630\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3417 - accuracy: 0.8621\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 1s 986us/step - loss: 0.3412 - accuracy: 0.8629\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 1s 961us/step - loss: 0.3409 - accuracy: 0.8618\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3402 - accuracy: 0.8618\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 1s 994us/step - loss: 0.3396 - accuracy: 0.8631\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 1s 953us/step - loss: 0.3398 - accuracy: 0.8612\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8640\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3392 - accuracy: 0.8636\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.3389 - accuracy: 0.8629\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.3386 - accuracy: 0.8640\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3383 - accuracy: 0.8631\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3378 - accuracy: 0.8631\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3376 - accuracy: 0.8634\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 1s 868us/step - loss: 0.3375 - accuracy: 0.8631\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 1s 985us/step - loss: 0.3373 - accuracy: 0.8629\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 1s 832us/step - loss: 0.3369 - accuracy: 0.8635\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 1s 932us/step - loss: 0.3368 - accuracy: 0.8633\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 1s 896us/step - loss: 0.3366 - accuracy: 0.8627\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3369 - accuracy: 0.8627\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3361 - accuracy: 0.8625\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3365 - accuracy: 0.8648\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3363 - accuracy: 0.8641\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3360 - accuracy: 0.8640\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 0.3360 - accuracy: 0.8646\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3358 - accuracy: 0.8625\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3359 - accuracy: 0.8629\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 1s 912us/step - loss: 0.3357 - accuracy: 0.8625\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 1s 974us/step - loss: 0.3359 - accuracy: 0.8631\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3357 - accuracy: 0.8630\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.3352 - accuracy: 0.8630\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3357 - accuracy: 0.8640\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3356 - accuracy: 0.8624\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 1s 980us/step - loss: 0.3350 - accuracy: 0.8640\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 1s 839us/step - loss: 0.3351 - accuracy: 0.8622\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 1s 925us/step - loss: 0.3348 - accuracy: 0.8639\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3350 - accuracy: 0.8633\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3352 - accuracy: 0.8629\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 1s 827us/step - loss: 0.3351 - accuracy: 0.8631\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 1s 944us/step - loss: 0.3343 - accuracy: 0.8649\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 1s 826us/step - loss: 0.3347 - accuracy: 0.8625\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 1s 962us/step - loss: 0.3351 - accuracy: 0.8648\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 1s 875us/step - loss: 0.3350 - accuracy: 0.8636\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 1s 829us/step - loss: 0.3349 - accuracy: 0.8627\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 1s 817us/step - loss: 0.3350 - accuracy: 0.8622\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 1s 927us/step - loss: 0.3344 - accuracy: 0.8635\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 1s 924us/step - loss: 0.3347 - accuracy: 0.8656\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 1s 830us/step - loss: 0.3346 - accuracy: 0.8648\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 1s 836us/step - loss: 0.3344 - accuracy: 0.8639\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 1s 908us/step - loss: 0.3342 - accuracy: 0.8651\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 1s 861us/step - loss: 0.3342 - accuracy: 0.8634\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 1s 833us/step - loss: 0.3344 - accuracy: 0.8636\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3341 - accuracy: 0.8636\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 1s 894us/step - loss: 0.3343 - accuracy: 0.8633\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 1s 825us/step - loss: 0.3344 - accuracy: 0.8648\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 1s 831us/step - loss: 0.3342 - accuracy: 0.8641\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3341 - accuracy: 0.8639\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 1s 839us/step - loss: 0.3340 - accuracy: 0.8640\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 1s 825us/step - loss: 0.3338 - accuracy: 0.8646\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 1s 830us/step - loss: 0.3341 - accuracy: 0.8645\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 922us/step - loss: 0.3344 - accuracy: 0.8641\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 0.3340 - accuracy: 0.8643\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 1s 895us/step - loss: 0.3344 - accuracy: 0.8656\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 1s 828us/step - loss: 0.3341 - accuracy: 0.8650\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 1s 827us/step - loss: 0.3339 - accuracy: 0.8649\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 1s 825us/step - loss: 0.3338 - accuracy: 0.8644\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 1s 836us/step - loss: 0.3339 - accuracy: 0.8651\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 1s 922us/step - loss: 0.3341 - accuracy: 0.8640\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3340 - accuracy: 0.8641\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 1s 971us/step - loss: 0.3333 - accuracy: 0.8654\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 1s 1000us/step - loss: 0.3337 - accuracy: 0.8645\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 1s 937us/step - loss: 0.3339 - accuracy: 0.8644\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 1s 934us/step - loss: 0.3334 - accuracy: 0.8650\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 1s 967us/step - loss: 0.3340 - accuracy: 0.8643\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 1s 987us/step - loss: 0.3333 - accuracy: 0.8661\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3335 - accuracy: 0.8629\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 1s 998us/step - loss: 0.3338 - accuracy: 0.8650\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 1s 968us/step - loss: 0.3333 - accuracy: 0.8658\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 1s 947us/step - loss: 0.3338 - accuracy: 0.8650\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 1s 955us/step - loss: 0.3336 - accuracy: 0.8644\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 1s 964us/step - loss: 0.3337 - accuracy: 0.8639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8eaad6bca0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer='glorot_uniform', activation = 'relu', input_dim = 13))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer='glorot_uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer='glorot_uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "W1hvlo3-SlAO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HvWMJKSIUlSU"
   },
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4YSWohZUncg",
    "outputId": "e8e55b78-8d8f-4949-a8fa-047a8f74ada1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1512,   83],\n",
       "       [ 197,  208]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "rBy3-YAMUoT4"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (8000,) and (1,2000) not aligned: 8000 (dim 0) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# call protodash explainer\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# S contains indices of the selected prototypes\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# W contains importance weights associated with the selected prototypes\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m (W, S, _) \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/aix360/algorithms/protodash/PDASH.py:47\u001b[0m, in \u001b[0;36mProtodashExplainer.explain\u001b[0;34m(self, X, Y, m, kernelType, sigma)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexplain\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, m, kernelType\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mother\u001b[39m\u001b[38;5;124m'\u001b[39m, sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    Return prototypes for data X, Y.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m        m selected prototypes from X and their (unnormalized) importance weights\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m( \u001b[43mHeuristicSetSelection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernelType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/aix360/algorithms/protodash/PDASH_utils.py:182\u001b[0m, in \u001b[0;36mHeuristicSetSelection\u001b[0;34m(X, Y, m, kernelType, sigma)\u001b[0m\n\u001b[1;32m    180\u001b[0m         meanInnerProductX[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum( np\u001b[38;5;241m.\u001b[39mexp(np\u001b[38;5;241m.\u001b[39msquare(distX)\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m*\u001b[39m sigma\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)) ) \u001b[38;5;241m/\u001b[39m numX\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     M \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m     meanInnerProductX \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(M, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m M\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# move to features x observation format to be consistent with the earlier code version\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (8000,) and (1,2000) not aligned: 8000 (dim 0) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "from aix360.algorithms.protodash import ProtodashExplainer\n",
    "\n",
    "explainer = ProtodashExplainer()\n",
    "m = 3\n",
    "# call protodash explainer\n",
    "# S contains indices of the selected prototypes\n",
    "# W contains importance weights associated with the selected prototypes\n",
    "(W, S, _) = explainer.explain(y_pred, y_train, m=m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/aix360/algorithms/protodash/PDASH_utils.py:219: RuntimeWarning: invalid value encountered in true_divide\n",
      "  w = np.max(u / K, 0)\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/cvxopt/coneprog.py:2111: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if 'x' in initvals:\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/cvxopt/coneprog.py:2116: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if 's' in initvals:\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/cvxopt/coneprog.py:2131: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if 'y' in initvals:\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/cvxopt/coneprog.py:2136: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if 'z' in initvals:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  0.0000e+00 -2.0000e+04  4e+00  1e+00  0e+00\n",
      " 1:  0.0000e+00 -4.9980e+11  5e+11  3e-16  5e-09\n",
      " 2:  0.0000e+00 -4.9980e+09  5e+09  2e-16  1e-10\n",
      " 3:  0.0000e+00 -4.9980e+07  5e+07  0e+00  0e+00\n",
      " 4:  0.0000e+00 -4.9980e+05  5e+05  9e-17  2e-14\n",
      " 5:  0.0000e+00 -4.9980e+03  5e+03  0e+00  4e-15\n",
      " 6:  0.0000e+00 -4.9980e+01  5e+01  9e-17  4e-17\n",
      " 7:  0.0000e+00 -4.9980e-01  5e-01  2e-16  3e-20\n",
      " 8:  0.0000e+00 -4.9980e-03  5e-03  1e-16  4e-22\n",
      " 9:  0.0000e+00 -4.9980e-05  5e-05  1e-16  4e-24\n",
      "10:  0.0000e+00 -4.9980e-07  5e-07  9e-17  4e-26\n",
      "11:  0.0000e+00 -4.9980e-09  5e-09  9e-17  4e-28\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  0.0000e+00 -3.0000e+04  6e+00  1e+00  1e-01\n",
      " 1:  6.3409e-01 -1.0425e+05  2e+01  1e+00  1e-01\n",
      " 2:  5.3059e-01 -5.3416e+07  1e+04  1e+00  1e-01\n",
      " 3:  3.8719e+07 -1.0976e+15  1e+15  4e-13  7e-06\n",
      " 4:  3.8719e+07 -1.0977e+13  1e+13  3e-15  4e-06\n",
      " 5:  3.8719e+07 -1.0993e+11  1e+11  2e-16  7e-08\n",
      " 6:  3.8680e+07 -1.2622e+09  1e+09  2e-16  1e-09\n",
      " 7:  3.5293e+07 -1.6138e+08  2e+08  7e-17  2e-10\n",
      " 8:  3.5172e+03 -1.2494e+08  1e+08  1e-16  2e-12\n",
      " 9:  3.3765e+03 -1.2566e+06  1e+06  1e-16  5e-13\n",
      "10:  9.1247e+02 -1.4010e+04  1e+04  2e-16  3e-14\n",
      "11:  1.3452e+02 -2.7086e+02  4e+02  2e-16  7e-15\n",
      "12:  1.9089e+01 -2.2410e+01  4e+01  1e-16  8e-15\n",
      "13:  2.5889e+00 -3.3945e+00  6e+00  1e-16  1e-15\n",
      "14:  3.2062e-01 -5.2161e-01  8e-01  1e-16  4e-16\n",
      "15:  2.4574e-02 -9.2893e-02  1e-01  2e-16  2e-16\n",
      "16: -8.4110e-03 -2.3411e-02  1e-02  3e-16  3e-17\n",
      "17: -1.0563e-02 -1.1629e-02  1e-03  9e-17  1e-17\n",
      "18: -1.0585e-02 -1.0598e-02  1e-05  2e-16  4e-18\n",
      "19: -1.0585e-02 -1.0585e-02  1e-07  1e-16  2e-18\n",
      "20: -1.0585e-02 -1.0585e-02  1e-09  8e-17  4e-18\n",
      "Optimal solution found.\n",
      "   RowNumber  CustomerId Surname  CreditScore Geography  Gender  Age  Tenure  \\\n",
      "1          2    15647311    Hill          608     Spain  Female   41       1   \n",
      "2          3    15619304    Onio          502    France  Female   42       8   \n",
      "5          6    15574012     Chu          645     Spain    Male   44       8   \n",
      "\n",
      "     Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
      "1   83807.86              1          0               1        112542.58   \n",
      "2  159660.80              3          1               0        113931.57   \n",
      "5  113755.78              2          1               0        149756.71   \n",
      "\n",
      "   Exited     Weight  \n",
      "1       0  5000.0000  \n",
      "2       1  5000.0000  \n",
      "5       1     0.1455  \n",
      "(300, 100) (4000, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/cvxopt/coneprog.py:2111: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if 'x' in initvals:\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/cvxopt/coneprog.py:2116: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if 's' in initvals:\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/cvxopt/coneprog.py:2131: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if 'y' in initvals:\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/cvxopt/coneprog.py:2136: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if 'z' in initvals:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  0.0000e+00 -2.0000e+04  4e+00  1e+00  1e+00\n",
      " 1:  3.2221e+00 -8.5266e+04  2e+01  1e+00  1e+00\n",
      " 2:  2.7001e-01 -1.6914e+07  4e+03  1e+00  1e+00\n",
      " 3:  4.3897e+07 -3.9165e+14  4e+14  8e-13  8e-06\n",
      " 4:  4.3897e+07 -3.9165e+12  4e+12  8e-15  5e-06\n",
      " 5:  4.3894e+07 -3.9210e+10  4e+10  1e-16  5e-08\n",
      " 6:  4.3518e+07 -4.3607e+08  5e+08  3e-16  6e-10\n",
      " 7:  2.4531e+07 -2.8978e+07  5e+07  1e-16  7e-11\n",
      " 8:  3.6567e+06 -5.7170e+06  9e+06  9e-17  2e-12\n",
      " 9:  5.4550e+05 -5.8860e+05  1e+06  9e-17  6e-13\n",
      "10:  7.8453e+04 -8.8545e+04  2e+05  4e-17  4e-13\n",
      "11:  1.1222e+04 -1.2517e+04  2e+04  2e-16  1e-13\n",
      "12:  1.5941e+03 -1.8062e+03  3e+03  2e-16  5e-14\n",
      "13:  2.2267e+02 -2.6432e+02  5e+02  2e-16  1e-14\n",
      "14:  2.9593e+01 -4.0124e+01  7e+01  8e-17  0e+00\n",
      "15:  3.2462e+00 -6.6869e+00  1e+01  1e-16  9e-16\n",
      "16: -3.8432e-02 -1.4066e+00  1e+00  3e-16  7e-16\n",
      "17: -3.4476e-01 -4.9425e-01  1e-01  9e-17  3e-16\n",
      "18: -3.5526e-01 -3.5919e-01  4e-03  2e-16  1e-16\n",
      "19: -3.5527e-01 -3.5531e-01  4e-05  4e-17  5e-17\n",
      "20: -3.5527e-01 -3.5527e-01  4e-07  2e-16  5e-17\n",
      "21: -3.5527e-01 -3.5527e-01  4e-09  1e-16  2e-17\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  0.0000e+00 -3.0000e+04  6e+00  1e+00  1e+00\n",
      " 1:  5.8894e+00 -1.4435e+05  3e+01  1e+00  1e+00\n",
      " 2: -2.5861e-01 -7.3766e+06  1e+03  1e+00  1e+00\n",
      " 3:  9.5059e-01 -4.6431e+08  1e+05  1e+00  1e+00\n",
      " 4:  4.6414e+07 -1.1086e+16  1e+16  5e-13  7e-05\n",
      " 5:  4.6414e+07 -1.1086e+14  1e+14  5e-15  6e-05\n",
      " 6:  4.6414e+07 -1.1088e+12  1e+12  1e-16  1e-06\n",
      " 7:  4.6409e+07 -1.1309e+10  1e+10  5e-17  1e-08\n",
      " 8:  4.5972e+07 -3.3206e+08  4e+08  3e-16  3e-10\n",
      " 9:  8.2487e+06 -1.1901e+08  1e+08  1e-16  1e-10\n",
      "10:  2.7745e+06 -5.3081e+06  8e+06  2e-16  7e-12\n",
      "11:  4.1102e+05 -4.4387e+05  9e+05  2e-16  5e-13\n",
      "12:  5.9104e+04 -6.6801e+04  1e+05  1e-16  4e-14\n",
      "13:  8.4480e+03 -9.4441e+03  2e+04  2e-16  7e-14\n",
      "14:  1.1982e+03 -1.3638e+03  3e+03  3e-16  3e-14\n",
      "15:  1.6663e+02 -2.0025e+02  4e+02  2e-16  9e-15\n",
      "16:  2.1831e+01 -3.0674e+01  5e+01  9e-17  4e-15\n",
      "17:  2.2316e+00 -5.2332e+00  7e+00  8e-17  2e-15\n",
      "18: -1.5274e-01 -1.1659e+00  1e+00  9e-17  1e-16\n",
      "19: -3.5994e-01 -4.5999e-01  1e-01  1e-16  1e-16\n",
      "20: -3.6968e-01 -3.7995e-01  1e-02  2e-16  5e-17\n",
      "21: -3.7030e-01 -3.7057e-01  3e-04  3e-16  1e-16\n",
      "22: -3.7030e-01 -3.7030e-01  3e-06  2e-16  5e-17\n",
      "23: -3.7030e-01 -3.7030e-01  3e-08  2e-16  5e-17\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -0.0000e+00 -4.0000e+04  8e+00  1e+00  1e+00\n",
      " 1:  9.3221e+00 -2.1867e+05  4e+01  1e+00  1e+00\n",
      " 2: -2.7071e-01 -6.2612e+06  1e+03  1e+00  1e+00\n",
      " 3:  2.3451e+00 -2.0323e+08  4e+04  1e+00  1e+00\n",
      " 4:  1.7674e+00 -7.3334e+11  3e+08  1e+00  1e+00\n",
      " 5:  4.6015e+07 -5.9700e+18  6e+18  3e-13  3e-02\n",
      " 6:  4.6015e+07 -5.9700e+16  6e+16  3e-15  2e-02\n",
      " 7:  4.6015e+07 -5.9700e+14  6e+14  2e-16  4e-04\n",
      " 8:  4.6015e+07 -5.9703e+12  6e+12  9e-17  3e-06\n",
      " 9:  4.6014e+07 -6.0011e+10  6e+10  2e-16  4e-08\n",
      "10:  4.5901e+07 -9.0781e+08  1e+09  1e-16  1e-09\n",
      "11:  3.9137e+07 -2.6189e+08  3e+08  8e-17  1e-09\n",
      "12:  3.7830e+06 -1.6312e+08  2e+08  3e-16  1e-10\n",
      "13:  1.1693e+06 -4.1683e+06  5e+06  2e-16  4e-12\n",
      "14:  1.7665e+05 -2.1074e+05  4e+05  1e-16  4e-13\n",
      "15:  2.5265e+04 -2.7971e+04  5e+04  2e-16  9e-14\n",
      "16:  3.6001e+03 -4.0440e+03  8e+03  8e-17  8e-14\n",
      "17:  5.0722e+02 -5.8725e+02  1e+03  2e-16  2e-14\n",
      "18:  6.9248e+01 -8.7506e+01  2e+02  2e-16  7e-15\n",
      "19:  8.5002e+00 -1.3901e+01  2e+01  2e-16  3e-15\n",
      "20:  5.5238e-01 -2.5990e+00  3e+00  1e-16  1e-15\n",
      "21: -3.1688e-01 -7.1435e-01  4e-01  2e-16  2e-16\n",
      "22: -3.6885e-01 -4.3770e-01  7e-02  2e-16  2e-16\n",
      "23: -3.7656e-01 -3.9196e-01  2e-02  2e-16  2e-16\n",
      "24: -3.7664e-01 -3.7682e-01  2e-04  2e-16  1e-16\n",
      "25: -3.7664e-01 -3.7664e-01  2e-06  1e-16  1e-16\n",
      "26: -3.7664e-01 -3.7664e-01  2e-08  3e-16  7e-17\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  0.0000e+00 -5.0000e+04  1e+01  1e+00  1e+00\n",
      " 1:  1.3506e+01 -3.0820e+05  6e+01  1e+00  1e+00\n",
      " 2: -2.5046e-01 -6.0247e+06  1e+03  1e+00  1e+00\n",
      " 3:  3.4951e+00 -1.2157e+08  2e+04  1e+00  1e+00\n",
      " 4:  5.2379e+00 -1.2733e+11  3e+07  1e+00  1e+00\n",
      " 5:  4.8704e+07 -2.1353e+18  2e+18  6e-13  1e-02\n",
      " 6:  4.8704e+07 -2.1353e+16  2e+16  7e-15  1e-02\n",
      " 7:  4.8704e+07 -2.1353e+14  2e+14  2e-16  1e-04\n",
      " 8:  4.8704e+07 -2.1357e+12  2e+12  2e-16  1e-06\n",
      " 9:  4.8699e+07 -2.1766e+10  2e+10  4e-16  1e-08\n",
      "10:  4.8239e+07 -6.2353e+08  7e+08  2e-16  5e-10\n",
      "11:  1.7641e+07 -1.5589e+08  2e+08  2e-16  2e-09\n",
      "12:  4.6226e+06 -1.0162e+07  1e+07  1e-16  1e-10\n",
      "13:  6.8723e+05 -7.5421e+05  1e+06  2e-16  7e-13\n",
      "14:  9.8870e+04 -1.1150e+05  2e+05  1e-16  3e-13\n",
      "15:  1.4144e+04 -1.5779e+04  3e+04  1e-16  1e-13\n",
      "16:  2.0108e+03 -2.2729e+03  4e+03  2e-16  4e-14\n",
      "17:  2.8153e+02 -3.3191e+02  6e+02  2e-16  1e-14\n",
      "18:  3.7703e+01 -5.0125e+01  9e+01  2e-16  5e-15\n",
      "19:  4.2787e+00 -8.2456e+00  1e+01  1e-16  3e-15\n",
      "20:  5.4510e-02 -1.6812e+00  2e+00  2e-16  7e-16\n",
      "21: -3.5895e-01 -5.5641e-01  2e-01  2e-16  2e-16\n",
      "22: -3.7871e-01 -3.9368e-01  1e-02  9e-17  5e-17\n",
      "23: -3.8024e-01 -3.8132e-01  1e-03  2e-16  1e-16\n",
      "24: -3.8026e-01 -3.8027e-01  1e-05  2e-16  2e-16\n",
      "25: -3.8026e-01 -3.8026e-01  1e-07  2e-16  6e-17\n",
      "Optimal solution found.\n",
      "[3940 2539 2168 2189 1170] [0.20611975 0.24524152 0.19131865 0.17175151 0.16123794]\n"
     ]
    }
   ],
   "source": [
    "explainer = ProtodashExplainer()\n",
    "(W, S, _) = explainer.explain(y_pred, y_pred, m=3)\n",
    "dfs = dataset.iloc[S].copy()\n",
    "dfs[\"Weight\"] = W\n",
    "print(dfs)\n",
    "from aix360.algorithms.protodash import get_Gaussian_Data\n",
    "# Gaussian (simulated) data example\n",
    "# generate normalized gaussian data X, Y with 100 features and 300 & 4000 observations respectively\n",
    "(X, Y) = get_Gaussian_Data(100, 300, 4000)\n",
    "print(X.shape, Y.shape)\n",
    "(W, S, _) = explainer.explain(X, Y, m=5, kernelType='Gaussian', sigma=2)\n",
    "print(S, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3940 2539 2168 2189 1170] [0.20611975 0.24524152 0.19131865 0.17175151 0.16123794]\n"
     ]
    }
   ],
   "source": [
    "print(S, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Weights of Prototypes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId Surname  CreditScore Geography  Gender  Age  Tenure  \\\n",
       "1          2    15647311    Hill          608     Spain  Female   41       1   \n",
       "2          3    15619304    Onio          502    France  Female   42       8   \n",
       "\n",
       "     Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
       "1   83807.86              1          0               1        112542.58   \n",
       "2  159660.80              3          1               0        113931.57   \n",
       "\n",
       "   Exited  Weights of Prototypes  \n",
       "1       0                    0.5  \n",
       "2       1                    0.5  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the prototypes along with their computed weights\n",
    "inc_prototypes = dataset.iloc[S, :].copy()\n",
    "# Compute normalized importance weights for prototypes\n",
    "inc_prototypes[\"Weights of Prototypes\"] = np.around(W/np.sum(W), 2) \n",
    "inc_prototypes\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "NomuraHack.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
